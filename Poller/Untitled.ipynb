{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fb5fe0a4761b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#saveClassifier()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mprocess_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-fb5fe0a4761b>\u001b[0m in \u001b[0;36mprocess_content\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnamedEnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mnamedEnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchic\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchic\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m     \"\"\"\n\u001b[1;32m-> 1008\u001b[1;33m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchic\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jchic\\appdata\\local\\programs\\python\\python39\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import pickle\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[5:]:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "            namedEnt.draw()\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "def saveClassifier():\n",
    "    save_class = open(\"classifier.pickle\", \"wb\")\n",
    "    pickle.dump(custom_sent_tokenizer, save_class)\n",
    "    save_class.close()\n",
    "    \n",
    "\n",
    "#saveClassifier()\n",
    "#process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Finding name...\n",
      "('Iraq', 'NNP')\n",
      "Found:\n",
      "Iraq Peshmerga fighters arrive in embattled Kobani\n",
      "\n",
      "Iraq\n",
      "\n",
      "\n",
      "\n",
      "('Peshmerga', 'NNP')\n",
      "Found:\n",
      "Iraq Peshmerga fighters arrive in embattled Kobani\n",
      "\n",
      "Peshmerga\n",
      "\n",
      "\n",
      "\n",
      "fighters\n",
      "NNS\n",
      "arrive\n",
      "VBP\n",
      "in\n",
      "IN\n",
      "embattled\n",
      "JJ\n",
      "Kobani\n",
      "NNP\n",
      "100\n",
      "CD\n",
      "feared\n",
      "VBN\n",
      "trapped\n",
      "VBN\n",
      "in\n",
      "IN\n",
      "('India', 'NNP')\n",
      "Found:\n",
      "100 feared trapped in India landslide debris\n",
      "\n",
      "India\n",
      "\n",
      "\n",
      "\n",
      "landslide\n",
      "NN\n",
      "debris\n",
      "NN\n",
      "('Carter', 'NNP')\n",
      "Found:\n",
      "Carter criticizes Obama on ISIS: 'We waited too long'\n",
      "\n",
      "Carter\n",
      "\n",
      "\n",
      "\n",
      "criticizes\n",
      "VBZ\n",
      "('Obama', 'NNP')\n",
      "Found:\n",
      "Carter criticizes Obama on ISIS: 'We waited too long'\n",
      "\n",
      "Obama\n",
      "\n",
      "\n",
      "\n",
      "on\n",
      "IN\n",
      "ISIS\n",
      "NNP\n",
      ":\n",
      "Error with tokenizing\n",
      "``\n",
      "``\n",
      "('Hong', 'NNP')\n",
      "Found:\n",
      "\"Hong Kong's youth arm with cell phones, umbrellas\"\n",
      "\n",
      "Hong\n",
      "\n",
      "\n",
      "\n",
      "('Kong', 'NNP')\n",
      "Found:\n",
      "\"Hong Kong's youth arm with cell phones, umbrellas\"\n",
      "\n",
      "Kong\n",
      "\n",
      "\n",
      "\n",
      "'s\n",
      "POS\n",
      "youth\n",
      "NN\n",
      "arm\n",
      "NN\n",
      "with\n",
      "IN\n",
      "cell\n",
      "NN\n",
      "phones\n",
      "NNS\n",
      ",\n",
      "Error with tokenizing\n",
      "'Big\n",
      "POS\n",
      "('Bang', 'NNP')\n",
      "Found:\n",
      "'Big Bang Theory' star Kaley Cuoco weds\n",
      "\n",
      "Bang\n",
      "\n",
      "\n",
      "\n",
      "('Theory', 'NNP')\n",
      "Found:\n",
      "'Big Bang Theory' star Kaley Cuoco weds\n",
      "\n",
      "Theory\n",
      "\n",
      "\n",
      "\n",
      "'\n",
      "Error with tokenizing\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import state_union\n",
    "\n",
    "def findName(line):\n",
    "    \n",
    "    train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "    \n",
    "    custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "    \n",
    "    #text = inputFile.read()\n",
    "    \n",
    "    # tokenizing the input file (the main file)\n",
    "    tokenized = custom_sent_tokenizer.tokenize(line)[0]\n",
    "    #print(tokenized)\n",
    "    \n",
    "    # finding the names\n",
    "    try:\n",
    "        words = nltk.word_tokenize(tokenized)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
    "        #print(namedEnt)\n",
    "        #print(\"Broken down: \")\n",
    "        # determining if there's a name in the title\n",
    "        # that's such a broad ass descpritor (NNP)\n",
    "        for ent in namedEnt:\n",
    "            for entType in ent:\n",
    "                print(entType)\n",
    "                if entType[1] == \"NNP\":\n",
    "                    print(\"Found:\")\n",
    "                    print(line)\n",
    "                    print(entType[0])\n",
    "                    print(\"\\n\\n\")\n",
    "    except:\n",
    "        print(\"Error with tokenizing\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Starting...\")\n",
    "    \n",
    "inputFile = open(\"MainList-Copy1.txt\", \"r\")\n",
    "\n",
    "inputFile.seek(0, os.SEEK_SET)\n",
    "\n",
    "line = inputFile.readline()\n",
    "\n",
    "print(\"Finding name...\")\n",
    "while line:\n",
    "\n",
    "    #print(line)\n",
    "\n",
    "    if findName(line):\n",
    "        # if a name is found in the title, write it out to the new file\n",
    "        titleLine = line\n",
    "        urlLine = inputFile.readline()\n",
    "    else:\n",
    "        # otherwise, go the next title\n",
    "        line = inputFile.readline()\n",
    "    \n",
    "    line = inputFile.readline()\n",
    "\n",
    "inputFile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
